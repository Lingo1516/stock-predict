import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import io
import warnings
from dataclasses import dataclass
from datetime import datetime, time

warnings.filterwarnings("ignore")

# =========================
# Optional: Plotly
# =========================
PLOTLY_ERROR = ""
try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    HAS_PLOTLY = True
except Exception as e:
    HAS_PLOTLY = False
    PLOTLY_ERROR = str(e)

# =========================
# Optional: TW market calendar
# =========================
HAS_TW_CAL = False
try:
    import pandas_market_calendars as mcal
    HAS_TW_CAL = True
except Exception:
    HAS_TW_CAL = False

# =========================
# ML
# =========================
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import HistGradientBoostingRegressor

import ta

# =========================
# Config
# =========================
@dataclass
class Config:
    forecast_days: int = 10
    min_train_rows: int = 240

    # é æ¸¬è­·æ¬„ï¼šç”¨çœŸå¯¦æ­·å² MA20/ATR é™åˆ¶é æ¸¬ç¯„åœï¼Œé¿å…çˆ†èµ°
    atr_period: int = 14
    guard_atr_mult: float = 3.0

    # Ensemble model settings
    rf_estimators: int = 300
    rf_max_depth: int = 10
    hgb_max_iter: int = 500

    # Interval (about 80%)
    interval_z: float = 1.28

    # Scenario simulation
    sim_paths: int = 200
    sim_noise_mult: float = 1.0
    mean_revert_strength: float = 0.25

    # Turning rules (RSI + Bollinger)
    rsi_hi: float = 70.0
    rsi_lo: float = 30.0
    bb_window: int = 20
    bb_std: float = 2.0

CFG = Config()

# =========================
# Utils
# =========================
def safe_download(symbol: str, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
    df = yf.download(symbol, start=start, end=end, interval="1d", auto_adjust=True, progress=False)
    if df is None or df.empty:
        return pd.DataFrame()
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = [c[0] for c in df.columns]
    return df

def market_status(code: str) -> str:
    is_tw = code.upper().endswith(".TW")
    if is_tw and HAS_TW_CAL:
        try:
            cal = mcal.get_calendar("XTAI")
            now = pd.Timestamp.now(tz="Asia/Taipei")
            sched = cal.schedule(start_date=now.date(), end_date=now.date())
            if sched.empty:
                return "éäº¤æ˜“æ—¥"
            open_t = sched.iloc[0]["market_open"].tz_convert("Asia/Taipei")
            close_t = sched.iloc[0]["market_close"].tz_convert("Asia/Taipei")
            if open_t <= now <= close_t:
                return "ç›¤ä¸­"
            return "å·²æ”¶ç›¤"
        except Exception:
            pass

    now = datetime.now()
    if now.weekday() >= 5:
        return "éäº¤æ˜“æ—¥(æ¨æ¸¬)"
    if is_tw:
        if time(9, 0) <= now.time() <= time(13, 30):
            return "ç›¤ä¸­(æ¨æ¸¬)"
        return "å·²æ”¶ç›¤(æ¨æ¸¬)"
    return "æ—¥ç·šè³‡æ–™(ä¸åˆ¤æ–·ç›¤ä¸­)"

# =========================
# Feature Engineering (recursive-friendly)
# =========================
FEATURES = [
    "Ret1", "Ret5",
    "MA5", "MA10", "MA20", "MA60",
    "RSI",
    "Vol20",
    "VolChg"
]

def add_guard_indicators_real(df_raw: pd.DataFrame) -> pd.DataFrame:
    """åªåœ¨çœŸå¯¦æ­·å²è³‡æ–™ä¸Šç®— MA20/ATRï¼ˆè­·æ¬„ç”¨ï¼‰"""
    df = df_raw.copy()
    close = df["Close"].astype(float)
    df["MA20"] = close.rolling(20).mean()
    atr = ta.volatility.AverageTrueRange(df["High"], df["Low"], close, window=CFG.atr_period)
    df["ATR"] = atr.average_true_range()
    return df.dropna().copy()

def add_model_features(df_raw: pd.DataFrame) -> pd.DataFrame:
    """æ¨¡å‹ç‰¹å¾µï¼šåªç”¨ Close/Volume å¯æ¨é€²ç‰¹å¾µï¼ˆé¿å… High/Low è‡ªæˆ‘é¤µé£Ÿï¼‰"""
    df = df_raw.copy()
    close = df["Close"].astype(float)
    vol = df["Volume"].astype(float)

    df["Ret1"] = np.log(close).diff()
    df["Ret5"] = np.log(close).diff(5)

    df["MA5"] = close.rolling(5).mean()
    df["MA10"] = close.rolling(10).mean()
    df["MA20"] = close.rolling(20).mean()
    df["MA60"] = close.rolling(60).mean()

    df["RSI"] = ta.momentum.RSIIndicator(close, window=14).rsi()

    r1 = np.log(close).diff()
    df["Vol20"] = r1.rolling(20).std() * np.sqrt(252)

    df["VolChg"] = vol.pct_change().replace([np.inf, -np.inf], np.nan)

    return df.dropna().copy()

def compute_next_feature_row(close_hist: list[float], vol_hist: list[float]) -> np.ndarray:
    s = pd.Series(close_hist, dtype="float64")
    v = pd.Series(vol_hist, dtype="float64")

    ret1 = float(np.log(s.iloc[-1]) - np.log(s.iloc[-2])) if len(s) >= 2 else 0.0
    ret5 = float(np.log(s.iloc[-1]) - np.log(s.iloc[-6])) if len(s) >= 6 else 0.0

    ma5 = float(s.iloc[-5:].mean()) if len(s) >= 5 else float(s.mean())
    ma10 = float(s.iloc[-10:].mean()) if len(s) >= 10 else float(s.mean())
    ma20 = float(s.iloc[-20:].mean()) if len(s) >= 20 else float(s.mean())
    ma60 = float(s.iloc[-60:].mean()) if len(s) >= 60 else float(s.mean())

    if len(s) >= 15:
        rsi = float(ta.momentum.RSIIndicator(s, window=14).rsi().iloc[-1])
    else:
        rsi = 50.0

    r1 = np.log(s).diff().dropna()
    if len(r1) >= 20:
        vol20 = float(r1.iloc[-20:].std() * np.sqrt(252))
    elif len(r1) >= 2:
        vol20 = float(r1.std() * np.sqrt(252))
    else:
        vol20 = 0.0

    if len(v) >= 2 and v.iloc[-2] != 0:
        volchg = float(v.iloc[-1] / v.iloc[-2] - 1.0)
    else:
        volchg = 0.0

    return np.array([[ret1, ret5, ma5, ma10, ma20, ma60, rsi, vol20, volchg]], dtype="float64")

# =========================
# Ensemble + CV weighting
# =========================
def train_ensemble_with_cv(X: np.ndarray, y: np.ndarray, seed: int = 42):
    models = {
        "HGB": HistGradientBoostingRegressor(
            max_depth=6,
            learning_rate=0.05,
            max_iter=CFG.hgb_max_iter,
            random_state=seed
        ),
        "RF": RandomForestRegressor(
            n_estimators=CFG.rf_estimators,
            max_depth=CFG.rf_max_depth,
            min_samples_split=6,
            random_state=seed,
            n_jobs=-1
        )
    }

    tscv = TimeSeriesSplit(n_splits=5)
    cv_mae = {}

    for name, model in models.items():
        fold_mae = []
        for tr, te in tscv.split(X):
            model.fit(X[tr], y[tr])
            pred = model.predict(X[te])
            fold_mae.append(mean_absolute_error(y[te], pred))
        cv_mae[name] = float(np.mean(fold_mae))

    inv = {k: 1.0 / max(v, 1e-9) for k, v in cv_mae.items()}
    s = sum(inv.values())
    weights = {k: inv[k] / s for k in inv}

    trained = {}
    for name, model in models.items():
        model.fit(X, y)
        trained[name] = model

    return trained, weights, cv_mae

def ensemble_predict(models: dict, weights: dict, X: np.ndarray) -> np.ndarray:
    pred = None
    for name, model in models.items():
        p = model.predict(X)
        w = weights.get(name, 0.0)
        pred = p * w if pred is None else pred + p * w
    return pred

def estimate_sigma(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    resid = y_true - y_pred
    if resid.size >= 80:
        resid = resid[-80:]
    return float(np.std(resid))

# =========================
# 10-day recursive forecast
# =========================
def forecast_recursive(models, weights, df_feat: pd.DataFrame, df_raw: pd.DataFrame, df_guard: pd.DataFrame):
    future_dates = pd.bdate_range(start=df_feat.index[-1], periods=CFG.forecast_days + 1)[1:]

    close_hist = df_feat["Close"].astype(float).tolist()
    vol_hist = df_raw.loc[df_feat.index, "Volume"].astype(float).tolist()
    future_vol = float(np.mean(vol_hist[-20:])) if len(vol_hist) >= 20 else float(np.mean(vol_hist))

    last_close = float(df_feat["Close"].iloc[-1])

    # guard rails
    if not df_guard.empty:
        last_ma20 = float(df_guard["MA20"].iloc[-1])
        last_atr = float(df_guard["ATR"].iloc[-1])
    else:
        last_ma20 = float(df_feat["MA20"].iloc[-1])
        last_atr = 0.0

    upper = last_ma20 + CFG.guard_atr_mult * last_atr if last_atr > 0 else np.inf
    lower = last_ma20 - CFG.guard_atr_mult * last_atr if last_atr > 0 else -np.inf

    preds = []
    for _ in range(CFG.forecast_days):
        x_next = compute_next_feature_row(close_hist, vol_hist)
        p = float(ensemble_predict(models, weights, x_next)[0])
        p = min(max(p, lower), upper)
        preds.append(p)
        close_hist.append(p)
        vol_hist.append(future_vol)

    return future_dates, last_close, preds

# =========================
# RSI + Bollinger helpers
# =========================
def compute_rsi_bbands(close_series: pd.Series):
    rsi = ta.momentum.RSIIndicator(close_series, window=14).rsi()
    bb = ta.volatility.BollingerBands(close_series, window=CFG.bb_window, window_dev=CFG.bb_std)
    bb_h = bb.bollinger_hband()
    bb_l = bb.bollinger_lband()
    return rsi, bb_h, bb_l

# =========================
# Scenario simulation + turning stats (safe concat, no np.r_ for 2D)
# =========================
def simulate_paths_and_turning(df_raw: pd.DataFrame, future_dates, base_preds, sigma: float):
    T = int(len(base_preds))
    n = int(CFG.sim_paths)

    last_close = float(df_raw["Close"].iloc[-1])
    hist_close = df_raw["Close"].astype(float)

    if T <= 0:
        turn_df = pd.DataFrame(columns=["æ—¥æœŸ", "ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)", "ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)", "å¯èƒ½é«˜é»(%)_RSI+BB", "å¯èƒ½ä½é»(%)_RSI+BB"])
        summary = {"é€£æ¼²10å¤©æ©Ÿç‡(%)": 0.0, "é€£è·Œ10å¤©æ©Ÿç‡(%)": 0.0}
        return np.zeros((n, 0)), np.zeros((n, 0), dtype=int), turn_df, summary

    ma20_target = float(hist_close.tail(20).mean()) if len(hist_close) >= 20 else float(hist_close.mean())

    base = np.array(base_preds, dtype=float)
    # é€™è£¡æ˜¯ 1D safeï¼šnp.r_ ç”¨åœ¨ 1D æ²’å•é¡Œ
    base_ret = np.diff(np.log(np.r_[last_close, base]))  # length T

    rng = np.random.default_rng(42)
    paths = np.zeros((n, T), dtype=float)

    for i in range(n):
        c = last_close
        for t in range(T):
            noise = rng.normal(0.0, sigma / max(c, 1e-9)) * float(CFG.sim_noise_mult)
            mr = -float(CFG.mean_revert_strength) * ((c - ma20_target) / max(ma20_target, 1e-9)) / max(T, 1)
            r = float(base_ret[t]) + float(mr) + float(noise)
            c = c * np.exp(r)
            paths[i, t] = c

    # prev shape: (n, T)
    if T == 1:
        prev = np.full((n, 1), last_close, dtype=float)
    else:
        prev = np.concatenate([np.full((n, 1), last_close, dtype=float), paths[:, :-1]], axis=1)

    diff = paths - prev
    sign = np.where(diff >= 0, 1, -1).astype(int)

    p_all_up = float(np.mean(np.all(sign == 1, axis=1)) * 100.0)
    p_all_dn = float(np.mean(np.all(sign == -1, axis=1)) * 100.0)

    up_to_dn = np.zeros(T, dtype=float)
    dn_to_up = np.zeros(T, dtype=float)
    for t in range(1, T):
        up_to_dn[t] = float(np.mean((sign[:, t-1] == 1) & (sign[:, t] == -1)) * 100.0)
        dn_to_up[t] = float(np.mean((sign[:, t-1] == -1) & (sign[:, t] == 1)) * 100.0)

    top_prob = np.zeros(T, dtype=float)
    bot_prob = np.zeros(T, dtype=float)

    hist_tail = hist_close.tail(120).copy()

    for t in range(T - 1):  # needs next day
        top_hits = 0
        bot_hits = 0
        for i in range(n):
            sim_close = pd.concat(
                [hist_tail, pd.Series(paths[i, :t+1], index=future_dates[:t+1])],
                axis=0
            )
            rsi, bb_h, bb_l = compute_rsi_bbands(sim_close)

            c_t = float(sim_close.iloc[-1])
            rsi_t = float(rsi.iloc[-1]) if not np.isnan(rsi.iloc[-1]) else 50.0
            bh_t = float(bb_h.iloc[-1]) if not np.isnan(bb_h.iloc[-1]) else np.inf
            bl_t = float(bb_l.iloc[-1]) if not np.isnan(bb_l.iloc[-1]) else -np.inf

            overbought = (rsi_t >= CFG.rsi_hi) or (c_t >= bh_t)
            oversold = (rsi_t <= CFG.rsi_lo) or (c_t <= bl_t)

            next_down = paths[i, t+1] < paths[i, t]
            next_up = paths[i, t+1] > paths[i, t]

            if overbought and next_down:
                top_hits += 1
            if oversold and next_up:
                bot_hits += 1

        top_prob[t] = top_hits / n * 100.0
        bot_prob[t] = bot_hits / n * 100.0

    turn_df = pd.DataFrame({
        "æ—¥æœŸ": [d.date() for d in future_dates],
        "ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)": np.round(up_to_dn, 1),
        "ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)": np.round(dn_to_up, 1),
        "å¯èƒ½é«˜é»(%)_RSI+BB": np.round(top_prob, 1),
        "å¯èƒ½ä½é»(%)_RSI+BB": np.round(bot_prob, 1),
    })

    summary = {
        "é€£æ¼²10å¤©æ©Ÿç‡(%)": round(p_all_up, 2),
        "é€£è·Œ10å¤©æ©Ÿç‡(%)": round(p_all_dn, 2),
    }

    return paths, sign, turn_df, summary

# =========================
# Decision Summary Engine (ä½ è¦çš„ï¼šäººè©±çµè«– + å“ªå¤©è²·è³£ + å¼·åº¦ + è²·å¤šå°‘)
# =========================
def _clip_0_100(x: float) -> float:
    return float(max(0.0, min(100.0, x)))

def generate_trade_summary(
    turn_df: pd.DataFrame,
    result_df: pd.DataFrame,
    last_close: float,
    atr: float,
    capital: float,
    risk_pct: float
):
    """
    ä¾ turn_df + é æ¸¬è¡¨ + ATR ç”¢ç”Ÿï¼š
    - çµè«–ï¼ˆåå¤š/åç©º/ç›¤æ•´ï¼‰
    - Buy/Sell Strengthï¼ˆ0~100ï¼‰
    - æœ€ä½³è²·é»æ—¥ / æœ€ä½³è³£é»æ—¥
    - å»ºè­°è‚¡æ•¸ï¼ˆä¾é¢¨éšªèˆ‡åœæï¼‰
    """
    # ---- safety ----
    if turn_df is None or turn_df.empty or result_df is None or result_df.empty or atr <= 0:
        return {
            "bias": "è³‡æ–™ä¸è¶³",
            "buy_strength": 0.0,
            "sell_strength": 0.0,
            "best_buy_day": "N/A",
            "best_sell_day": "N/A",
            "shares": 0,
            "stop_price": 0.0,
            "summary_text": "è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•ç”¢ç”Ÿäº¤æ˜“çµè«–ã€‚"
        }

    # é æœŸå ±é…¬ï¼ˆä»¥æ¯ä¸€å¤©é æ¸¬åƒ¹ç›¸å° last_closeï¼‰
    pred_ret_pct = (result_df["é æ¸¬åƒ¹"].astype(float) / float(last_close) - 1.0) * 100.0

    # Buy / Sell åˆ†æ•¸ï¼ˆä½ è¦çš„è³ªæ€§+é‡åŒ–ï¼‰
    buy_scores = (
        0.45 * turn_df["ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)"].astype(float) +
        0.35 * turn_df["å¯èƒ½ä½é»(%)_RSI+BB"].astype(float) +
        0.20 * pred_ret_pct.clip(lower=0.0)
    )

    sell_scores = (
        0.45 * turn_df["ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)"].astype(float) +
        0.35 * turn_df["å¯èƒ½é«˜é»(%)_RSI+BB"].astype(float) +
        0.20 * (-pred_ret_pct).clip(lower=0.0)
    )

    buy_strength = _clip_0_100(float(buy_scores.max()))
    sell_strength = _clip_0_100(float(sell_scores.max()))

    # åå¤š/åç©º/ç›¤æ•´
    if buy_strength > sell_strength + 15:
        bias = "åå¤š"
    elif sell_strength > buy_strength + 15:
        bias = "åç©º"
    else:
        bias = "ç›¤æ•´"

    best_buy_idx = int(buy_scores.idxmax())
    best_sell_idx = int(sell_scores.idxmax())

    best_buy_day = str(result_df.loc[best_buy_idx, "æ—¥æœŸ"])
    best_sell_day = str(result_df.loc[best_sell_idx, "æ—¥æœŸ"])

    # å¼·åº¦æ–‡å­—
    def strength_label(x: float, side: str) -> str:
        if x >= 75:
            return f"å¼·çƒˆ{side}"
        if x >= 60:
            return f"æ˜ç¢º{side}"
        if x >= 40:
            return f"åå‘{side}"
        return "è§€æœ›"

    buy_label = strength_label(buy_strength, "è²·é€²")
    sell_label = strength_label(sell_strength, "è³£å‡º")

    # éƒ¨ä½è¨ˆç®—ï¼šé¢¨éšªé‡‘é¡ / æ¯è‚¡é¢¨éšª
    risk_amount = float(capital) * float(risk_pct)
    stop_price = float(last_close) - 2.5 * float(atr)
    risk_per_share = max(float(last_close) - float(stop_price), 1e-6)
    base_shares = int(risk_amount // risk_per_share)

    # ç”¨è²·é€²å¼·åº¦èª¿å€‰ä½ï¼ˆä½ è¦çš„ã€Œè¶•å¿«ã€å¼·åº¦å°æ‡‰åˆ°è²·å¤šå°‘ï¼‰
    if buy_strength >= 75:
        shares = int(base_shares * 1.3)
    elif buy_strength >= 60:
        shares = int(base_shares * 1.0)
    elif buy_strength >= 40:
        shares = int(base_shares * 0.5)
    else:
        shares = 0

    # å–å‡ºè²·é»åŸå› æ•¸å­—ï¼ˆæœ€é‡è¦ä¸‰å€‹ï¼‰
    row_buy = turn_df.loc[best_buy_idx]
    row_sell = turn_df.loc[best_sell_idx]

    buy_dn2up = float(row_buy["ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)"])
    buy_bottom = float(row_buy["å¯èƒ½ä½é»(%)_RSI+BB"])
    sell_up2dn = float(row_sell["ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)"])
    sell_top = float(row_sell["å¯èƒ½é«˜é»(%)_RSI+BB"])

    summary_text = (
        f"ã€æ•´é«”åˆ¤æ–·ã€‘{bias}\n"
        f"Buy Strengthï¼š{buy_strength:.0f}/100ï¼ˆ{buy_label}ï¼‰ï½œSell Strengthï¼š{sell_strength:.0f}/100ï¼ˆ{sell_label}ï¼‰\n\n"
        f"ã€æœ€ä½³è²·é»ã€‘{best_buy_day}\n"
        f"- ç”±è·Œè½‰æ¼²æ©Ÿç‡ï¼š{buy_dn2up:.1f}%\n"
        f"- å¯èƒ½ä½é»(RSI+å¸ƒæ—)ï¼š{buy_bottom:.1f}%\n\n"
        f"ã€æœ€ä½³è³£é»/é¢¨éšªæ—¥ã€‘{best_sell_day}\n"
        f"- ç”±æ¼²è½‰è·Œæ©Ÿç‡ï¼š{sell_up2dn:.1f}%\n"
        f"- å¯èƒ½é«˜é»(RSI+å¸ƒæ—)ï¼š{sell_top:.1f}%\n\n"
        f"ã€å»ºè­°éƒ¨ä½ï¼ˆä¾è³‡é‡‘/é¢¨éšª/åœæè‡ªå‹•è¨ˆç®—ï¼‰ã€‘\n"
        f"- è³‡é‡‘ï¼š{capital:,.0f}ï½œå–®ç­†é¢¨éšªï¼š{risk_pct*100:.0f}%ï¼ˆ{risk_amount:,.0f}ï¼‰\n"
        f"- å»ºè­°è²·é€²ï¼š{shares:,} è‚¡\n"
        f"- å»ºè­°åœæåƒ¹ï¼šç´„ {stop_price:.2f}ï¼ˆ= ç¾åƒ¹ - 2.5Ã—ATRï¼‰\n\n"
        f"ã€åº•ç·šã€‘è·Œç ´åœæåƒ¹ â†’ æœ¬æ¬¡åˆ¤æ–·å¤±æ•ˆï¼Œå¿…é ˆå‡ºå ´"
    )

    return {
        "bias": bias,
        "buy_strength": buy_strength,
        "sell_strength": sell_strength,
        "best_buy_day": best_buy_day,
        "best_sell_day": best_sell_day,
        "shares": shares,
        "stop_price": stop_price,
        "summary_text": summary_text
    }

# =========================
# Plot helpers
# =========================
def pick_top_days(df: pd.DataFrame, col: str, topk: int = 3):
    tmp = df.sort_values(col, ascending=False).head(topk)
    return tmp[["æ—¥æœŸ", col]]

def plot_history_and_pred(df_raw: pd.DataFrame, future_dates, preds):
    hist = df_raw[["Close"]].tail(120).copy()
    fut = pd.DataFrame({"Close": preds}, index=future_dates)
    return pd.concat([hist, fut], axis=0)

def plot_k_with_forecast(df_raw: pd.DataFrame, future_dates, preds, lo=None, hi=None):
    if not HAS_PLOTLY:
        return None
    dfp = df_raw.tail(160).copy()
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.06, row_heights=[0.72, 0.28],
                        subplot_titles=("Kç·š + 10æ—¥é æ¸¬", "æˆäº¤é‡"))

    fig.add_trace(go.Candlestick(
        x=dfp.index, open=dfp["Open"], high=dfp["High"], low=dfp["Low"], close=dfp["Close"], name="Kç·š"
    ), row=1, col=1)

    connect_x = [dfp.index[-1]] + list(future_dates)
    connect_y = [float(dfp["Close"].iloc[-1])] + list(preds)
    fig.add_trace(go.Scatter(x=connect_x, y=connect_y, name="é æ¸¬", line=dict(dash="dash", width=3)), row=1, col=1)

    if lo is not None and hi is not None:
        fig.add_trace(go.Scatter(
            x=list(future_dates) + list(future_dates)[::-1],
            y=list(hi) + list(lo)[::-1],
            fill="toself", opacity=0.18,
            line=dict(width=0),
            name="ç´„80%å€é–“"
        ), row=1, col=1)

    fig.add_trace(go.Bar(x=dfp.index, y=dfp["Volume"], name="Volume"), row=2, col=1)
    fig.update_layout(height=700, xaxis_rangeslider_visible=False, hovermode="x unified")
    return fig

# =========================
# Streamlit App
# =========================
st.set_page_config(page_title="AI 10æ—¥è¶¨å‹¢åˆ¤å®šï¼ˆå«è²·è³£çµè«–ï¼‰", layout="wide", page_icon="ğŸ“ˆ")
st.title("ğŸ“ˆ AI 10æ—¥è¶¨å‹¢åˆ¤å®šï¼ˆå«è²·è³£çµè«–ã€å¼·åº¦ã€è²·å¤šå°‘ã€åœæï¼‰")
st.caption("é€™ç‰ˆæœƒç›´æ¥çµ¦ä½ å¹¾å¥çµè«–ï¼šå“ªå¤©è²·ã€å“ªå¤©è³£ã€å¼·åº¦å¤šå¤§ã€å»ºè­°è²·å¤šå°‘ï¼ˆä¾è³‡é‡‘100è¬/é¢¨éšª10%è¨ˆç®—ï¼‰ã€‚")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    data_source = st.radio("è³‡æ–™ä¾†æº", ["è‡ªå‹•ä¸‹è¼‰ (yfinance)", "æ‰‹å‹•è²¼ä¸ŠCSVè³‡æ–™"])

    show_interval = st.checkbox("é¡¯ç¤ºé æ¸¬å€é–“ï¼ˆç´„80%ï¼‰", value=True)
    show_plotly = st.checkbox("ä½¿ç”¨ Plotly K ç·šåœ–ï¼ˆéœ€ plotlyï¼‰", value=True)

    st.divider()
    st.subheader("ğŸ’° é¢¨æ§è¨­å®š")
    capital = st.number_input("è³‡é‡‘", min_value=0.0, value=1_000_000.0, step=50_000.0)
    risk_pct = st.slider("å–®ç­†é¢¨éšª (%)", 0.1, 20.0, 10.0, 0.1) / 100.0

    st.divider()
    st.subheader("ğŸ§ª æ¨¡æ“¬è¨­å®š")
    CFG.sim_paths = st.slider("å¤šæƒ…å¢ƒè·¯å¾‘æ•¸", 50, 400, CFG.sim_paths, 50)
    CFG.mean_revert_strength = st.slider("å‡å€¼å›æ­¸å¼·åº¦", 0.0, 0.8, CFG.mean_revert_strength, 0.05)
    CFG.sim_noise_mult = st.slider("æ¨¡æ“¬å™ªéŸ³å€ç‡", 0.3, 2.0, CFG.sim_noise_mult, 0.1)

    st.divider()
    if data_source == "è‡ªå‹•ä¸‹è¼‰ (yfinance)":
        code = st.text_input("è‚¡ç¥¨ä»£è™Ÿï¼ˆå°è‚¡è¼¸å…¥ 2330ã€ç¾è‚¡ AAPLï¼‰", "2330").strip()
        if code.isdigit():
            code = code + ".TW"
        code = code.upper()
        lookback_days = st.selectbox("è¨“ç·´è³‡æ–™é‡ï¼ˆè¶Šå¤šè¶Šç©©ã€è¶Šæ…¢ï¼‰", [600, 900, 1200, 1600, 2000], index=2)

        st.write(f"å¸‚å ´ç‹€æ…‹ï¼š{market_status(code)}ï¼ˆæç¤ºç”¨ï¼›é æ¸¬åŸºæ–¼æ—¥ç·šï¼‰")
        st.write(f"é æ¸¬äº¤æ˜“æ—¥æ•¸ï¼š{CFG.forecast_days}")
    else:
        st.info("CSV éœ€å« Date, Open, High, Low, Close, Volume æ¬„ä½ã€‚")

run_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True)

if run_btn:
    # ===== load data =====
    if data_source == "æ‰‹å‹•è²¼ä¸ŠCSVè³‡æ–™":
        manual = st.text_area("è²¼ä¸Š CSVï¼ˆéœ€å« Date, Open, High, Low, Close, Volumeï¼‰", height=240)
        if not manual.strip():
            st.error("è«‹å…ˆè²¼ä¸Š CSVã€‚")
            st.stop()
        try:
            df_raw = pd.read_csv(io.StringIO(manual))
            df_raw["Date"] = pd.to_datetime(df_raw["Date"])
            df_raw = df_raw.set_index("Date").sort_index()
        except Exception as e:
            st.error(f"CSV è§£æå¤±æ•—ï¼š{e}")
            st.stop()
    else:
        end = pd.Timestamp(datetime.today().date()) + pd.Timedelta(days=1)
        start = end - pd.Timedelta(days=int(lookback_days))
        with st.spinner("ä¸‹è¼‰è³‡æ–™ä¸­..."):
            df_raw = safe_download(code, start, end)
        if df_raw.empty:
            st.error("è³‡æ–™ä¸‹è¼‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä»£è™Ÿæˆ–ç¶²è·¯ã€‚")
            st.stop()

    # ===== features =====
    df_guard = add_guard_indicators_real(df_raw)
    df_feat = add_model_features(df_raw)

    if len(df_feat) < CFG.min_train_rows:
        st.error("æœ‰æ•ˆæ¨£æœ¬ä¸è¶³ï¼šè«‹èª¿é«˜è¨“ç·´è³‡æ–™é‡æˆ–æ›æ¨™çš„ã€‚")
        st.stop()

    # ===== train =====
    with st.spinner("è¨“ç·´ Ensemble + è¨ˆç®—æ®˜å·®æ³¢å‹•ä¸­..."):
        X = df_feat[FEATURES].values
        y = df_feat["Close"].values
        models, weights, cv_mae = train_ensemble_with_cv(X, y)
        y_pred = ensemble_predict(models, weights, X)
        sigma = estimate_sigma(y, y_pred)

    # ===== forecast =====
    with st.spinner("é€²è¡Œ 10 æ—¥éè¿´é æ¸¬ä¸­..."):
        future_dates, last_close, base_preds = forecast_recursive(models, weights, df_feat, df_raw, df_guard)

    base_hi = [p + CFG.interval_z * sigma for p in base_preds]
    base_lo = [p - CFG.interval_z * sigma for p in base_preds]

    result_df = pd.DataFrame({
        "æ—¥æœŸ": [d.date() for d in future_dates],
        "é æ¸¬åƒ¹": np.round(base_preds, 2),
        "æ¼²è·Œå¹…(ç›¸å°æ˜¨æ”¶)": [f"{(p - last_close) / last_close * 100:+.2f}%" for p in base_preds],
        "å€é–“ä¸‹ç•Œ(ç´„80%)": np.round(base_lo, 2),
        "å€é–“ä¸Šç•Œ(ç´„80%)": np.round(base_hi, 2),
    })

    # ===== simulate + turning =====
    with st.spinner("å¤šæƒ…å¢ƒè·¯å¾‘æ¨¡æ“¬ + è½‰æŠ˜æ©Ÿç‡çµ±è¨ˆä¸­..."):
        paths, sign, turn_df, summary_prob = simulate_paths_and_turning(df_raw, future_dates, base_preds, sigma)

    # ===== summary engine (ä½ è¦çš„çµè«–) =====
    atr_val = float(df_guard["ATR"].iloc[-1]) if (df_guard is not None and not df_guard.empty and "ATR" in df_guard.columns) else 0.0
    decision = generate_trade_summary(
        turn_df=turn_df,
        result_df=result_df,
        last_close=float(last_close),
        atr=float(atr_val),
        capital=float(capital),
        risk_pct=float(risk_pct)
    )

    # ===== output =====
    st.subheader("ğŸ§¾ äº¤æ˜“æ±ºç­–æ‘˜è¦ï¼ˆä½ è¦çš„çµè«–å°±åœ¨é€™è£¡ï¼‰")
    st.success(decision["summary_text"])

    cA, cB, cC = st.columns(3)
    cA.metric("é€£æ¼²10å¤©æ©Ÿç‡", f"{summary_prob.get('é€£æ¼²10å¤©æ©Ÿç‡(%)', 0.0):.2f}%")
    cB.metric("é€£è·Œ10å¤©æ©Ÿç‡", f"{summary_prob.get('é€£è·Œ10å¤©æ©Ÿç‡(%)', 0.0):.2f}%")
    cC.metric("ATRï¼ˆåœæç”¨ï¼‰", f"{atr_val:.4f}" if atr_val > 0 else "N/A")

    st.subheader("ğŸ“Œ æ¨¡å‹æ‘˜è¦ï¼ˆåƒè€ƒç”¨ï¼‰")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("æœ€å¾Œæ”¶ç›¤åƒ¹", f"{last_close:.2f}")
    c2.metric("CV MAE (HGB)", f"{cv_mae.get('HGB', np.nan):.3f}")
    c3.metric("CV MAE (RF)", f"{cv_mae.get('RF', np.nan):.3f}")
    c4.metric("sigmaï¼ˆæ®˜å·®æ³¢å‹•ï¼‰", f"{sigma:.4f}")

    st.write(f"æ¬Šé‡ï¼šHGB **{weights.get('HGB', 0):.2f}**ï½œRF **{weights.get('RF', 0):.2f}**")

    st.subheader("ğŸ”® 10 å€‹äº¤æ˜“æ—¥é æ¸¬ï¼ˆåŸºæº–è·¯å¾‘ï¼‰")
    st.dataframe(
        result_df if show_interval else result_df.drop(columns=["å€é–“ä¸‹ç•Œ(ç´„80%)", "å€é–“ä¸Šç•Œ(ç´„80%)"]),
        use_container_width=True
    )

    st.subheader("ğŸ“Š è½‰æŠ˜æ©Ÿç‡æ˜ç´°ï¼ˆ10å¤©é€æ—¥ï¼‰")
    st.dataframe(turn_df, use_container_width=True)

    st.markdown("**æ–¹å‘è½‰æŠ˜ Top 3ï¼ˆç”±æ¼²è½‰è·Œ / ç”±è·Œè½‰æ¼²ï¼‰**")
    t1, t2 = st.columns(2)
    with t1:
        st.write("ç”±æ¼²è½‰è·Œæ©Ÿç‡æœ€é«˜æ—¥ï¼š")
        st.table(pick_top_days(turn_df, "ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)", 3))
    with t2:
        st.write("ç”±è·Œè½‰æ¼²æ©Ÿç‡æœ€é«˜æ—¥ï¼š")
        st.table(pick_top_days(turn_df, "ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)", 3))

    st.markdown("**æŠ€è¡“é¢è½‰æŠ˜ Top 3ï¼ˆRSI + å¸ƒæ—å¸¶ï¼‰**")
    b1, b2 = st.columns(2)
    with b1:
        st.write("å¯èƒ½é«˜é»ï¼š")
        st.table(pick_top_days(turn_df, "å¯èƒ½é«˜é»(%)_RSI+BB", 3))
    with b2:
        st.write("å¯èƒ½ä½é»ï¼š")
        st.table(pick_top_days(turn_df, "å¯èƒ½ä½é»(%)_RSI+BB", 3))

    st.subheader("ğŸ“ˆ èµ°å‹¢ï¼ˆæ­·å² + é æ¸¬ï¼‰")
    merged = plot_history_and_pred(df_raw, future_dates, base_preds)
    st.line_chart(merged)

    if show_plotly and HAS_PLOTLY:
        fig = plot_k_with_forecast(
            df_raw, future_dates, base_preds,
            base_lo if show_interval else None,
            base_hi if show_interval else None
        )
        st.plotly_chart(fig, use_container_width=True)
    elif show_plotly and not HAS_PLOTLY:
        st.warning(f"æœªå®‰è£ plotlyï¼š{PLOTLY_ERROR}")

st.caption("âš ï¸ å…è²¬è²æ˜ï¼šæœ¬å·¥å…·åƒ…ä¾›ç ”ç©¶èˆ‡å­¸ç¿’ï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚")
