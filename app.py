import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import ta
from datetime import datetime
import time
from ta.volatility import BollingerBands
from ta.trend import ADXIndicator
from collections import deque

# è‚¡ç¥¨ä»£è™Ÿåˆ°ä¸­æ–‡åç¨±ç°¡æ˜“å°ç…§å­—å…¸ï¼Œå¯è‡ªè¡Œæ“´å……
stock_name_dict = {
    "2330.TW": "å°ç£ç©é«”é›»è·¯è£½é€ è‚¡ä»½æœ‰é™å…¬å¸",
    "2317.TW": "é´»æµ·ç²¾å¯†å·¥æ¥­è‚¡ä»½æœ‰é™å…¬å¸",
    "2412.TW": "ä¸­è¯é›»ä¿¡è‚¡ä»½æœ‰é™å…¬å¸",
}

@st.cache_data
def predict_next_5(stock, days, decay_factor):
    try:
        end = pd.Timestamp(datetime.today().date())
        # æ“´å±•æ­·å²æ•¸æ“šç¯„åœè‡³è‡³å°‘ 5 å¹´
        start = end - pd.Timedelta(days=max(days, 365 * 5)) # ç¢ºä¿è‡³å°‘5å¹´æ•¸æ“š
        max_retries = 5 # å¢åŠ é‡è©¦æ¬¡æ•¸
        df, twii, sp = None, None, None

        for attempt in range(max_retries):
            try:
                df = yf.download(stock, start=start, end=end + pd.Timedelta(days=1),
                                 interval="1d", auto_adjust=True, progress=False)
                twii = yf.download("^TWII", start=start, end=end + pd.Timedelta(days=1),
                                  interval="1d", auto_adjust=True, progress=False)
                sp = yf.download("^GSPC", start=start, end=end + pd.Timedelta(days=1),
                                interval="1d", auto_adjust=True, progress=False)
                if not (df.empty or twii.empty or sp.empty):
                    break
            except Exception as e:
                st.warning(f"å˜—è©¦ {attempt + 1}/{max_retries} ä¸‹è¼‰å¤±æ•—: {e}")
                time.sleep(3) # å¢åŠ ç­‰å¾…æ™‚é–“

            if attempt == max_retries - 1:
                st.error(f"ç„¡æ³•ä¸‹è¼‰è³‡æ–™ï¼š{stock}ï¼Œè«‹æª¢æŸ¥è‚¡ç¥¨ä»£è™Ÿæˆ–ç¶²è·¯é€£ç·šã€‚")
                return None, None, None

        # æ›´å¥å£¯çš„ç¼ºå¤±å€¼è™•ç†ï¼šç·šæ€§æ’å€¼
        if df is not None and not df.empty:
            df = df.interpolate(method='linear', limit_direction='both')
            df = df.fillna(method='bfill').fillna(method='ffill') # å†æ¬¡å¡«å……å¯èƒ½å­˜åœ¨çš„é–‹é ­æˆ–çµå°¾NaN

        if df is None or len(df) < 100: # æé«˜æ•¸æ“šé‡ä¸è¶³çš„é–¾å€¼
            st.error(f"è³‡æ–™ä¸è¶³ï¼Œåƒ…æœ‰ {len(df) if df is not None else 0} è¡Œæ•¸æ“šã€‚è«‹ç¢ºä¿è‚¡ç¥¨ä»£è™Ÿæ­£ç¢ºä¸”æœ‰è¶³å¤ çš„æ­·å²æ•¸æ“šã€‚")
            return None, None, None

        if isinstance(df.columns, pd.MultiIndex):
            df.columns = [col[0] for col in df.columns]
        if isinstance(twii.columns, pd.MultiIndex):
            twii.columns = [col[0] for col in twii.columns]
        if isinstance(sp.columns, pd.MultiIndex):
            sp.columns = [col[0] for col in sp.columns]

        close = df["Close"].squeeze() if "Close" in df.columns else df.iloc[:, 3].squeeze()
        df["TWII_Close"] = twii["Close"].reindex(df.index, method="ffill").fillna(method="bfill")
        df["SP500_Close"] = sp["Close"].reindex(df.index, method="ffill").fillna(method="bfill")

        # ç¢ºä¿TWII_Closeå’ŒSP500_Closeæ²’æœ‰NaN
        if df["TWII_Close"].isnull().any() or df["SP500_Close"].isnull().any():
            st.error("å¸‚å ´æŒ‡æ•¸æ•¸æ“šç¼ºå¤±ï¼Œç„¡æ³•é€²è¡Œé æ¸¬ã€‚")
            return None, None, None

        df["MA5"] = close.rolling(5, min_periods=1).mean()
        df["MA10"] = close.rolling(10, min_periods=1).mean()
        df["MA20"] = close.rolling(20, min_periods=1).mean()
        df["MA60"] = close.rolling(60, min_periods=1).mean() # æ–°å¢MA60

        # å„ªåŒ– ta åº«ç•°å¸¸è™•ç†ï¼Œç¢ºä¿æ‰‹å‹•è¨ˆç®—é‚è¼¯ä¸€è‡´
        try:
            df["RSI"] = ta.momentum.RSIIndicator(close, window=14).rsi()
        except Exception as e:
            st.warning(f"RSIè¨ˆç®—å¤±æ•—ï¼Œå˜—è©¦æ‰‹å‹•è¨ˆç®—: {e}")
            delta = close.diff()
            gain = delta.where(delta > 0, 0).rolling(14, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(14, min_periods=1).mean()
            rs = gain / loss
            df["RSI"] = 100 - (100 / (1 + rs))

        try:
            macd = ta.trend.MACD(close)
            df["MACD"] = macd.macd()
            df["MACD_Signal"] = macd.macd_signal()
            df["MACD_Hist"] = macd.macd_diff() # æ–°å¢MACDæŸ±ç‹€åœ–
        except Exception as e:
            st.warning(f"MACDè¨ˆç®—å¤±æ•—ï¼Œå˜—è©¦æ‰‹å‹•è¨ˆç®—: {e}")
            ema12 = close.ewm(span=12, adjust=False).mean()
            ema26 = close.ewm(span=26, adjust=False).mean()
            df["MACD"] = ema12 - ema26
            df["MACD_Signal"] = df["MACD"].ewm(span=9, adjust=False).mean()
            df["MACD_Hist"] = df["MACD"] - df["MACD_Signal"]

        bb_indicator = BollingerBands(close, window=20, window_dev=2)
        df["BB_High"] = bb_indicator.bollinger_hband()
        df["BB_Low"] = bb_indicator.bollinger_lband()
        df["BB_Mid"] = bb_indicator.bollinger_mavg() # æ–°å¢å¸ƒæ—ä¸­è»Œ
        df["BB_Width"] = bb_indicator.bollinger_wband() # æ–°å¢å¸ƒæ—å¸¶å¯¬åº¦

        adx_indicator = ADXIndicator(df["High"], df["Low"], close, window=14)
        df["ADX"] = adx_indicator.adx()
        df["DIP"] = adx_indicator.plus_di() # æ–°å¢+DI
        df["DIM"] = adx_indicator.minus_di() # æ–°å¢-DI

        # æ–°å¢KDJæŒ‡æ¨™
        # è¨ˆç®—RSV
        low_14 = df['Low'].rolling(window=14).min()
        high_14 = df['High'].rolling(window=14).max()
        df['RSV'] = (close - low_14) / (high_14 - low_14) * 100
        # è¨ˆç®—Kå€¼
        df['K'] = df['RSV'].ewm(com=2, adjust=False).mean()
        # è¨ˆç®—Då€¼
        df['D'] = df['K'].ewm(com=2, adjust=False).mean()
        # è¨ˆç®—Jå€¼
        df['J'] = 3 * df['K'] - 2 * df['D']

        df["Prev_Close"] = close.shift(1)
        for i in range(1, 6): # å¢åŠ æ»¯å¾Œå¤©æ•¸åˆ°5å¤©
            df[f"Prev_Close_Lag{i}"] = close.shift(i)

        # æ”¹é€²æˆäº¤é‡ç¼ºå¤±è™•ç†
        if "Volume" in df.columns and not df["Volume"].isnull().all():
            df["Volume_MA"] = df["Volume"].rolling(10, min_periods=1).mean()
            df["Volume_Change"] = df["Volume"].pct_change()
        else:
            st.warning("æˆäº¤é‡æ•¸æ“šç¼ºå¤±æˆ–ç‚ºç©ºï¼Œå°‡ä½¿ç”¨0å¡«å……æˆäº¤é‡ç›¸é—œç‰¹å¾µã€‚")
            df["Volume"] = 0 # ç¢ºä¿Volumeåˆ—å­˜åœ¨ï¼Œé¿å…å¾ŒçºŒè¨ˆç®—å ±éŒ¯
            df["Volume_MA"] = 0
            df["Volume_Change"] = 0

        df["Volatility"] = close.rolling(10, min_periods=1).std()
        df["Daily_Return"] = close.pct_change()

        # å¼•å…¥åŸºæœ¬é¢æ•¸æ“š (ç°¡åŒ–ç¤ºä¾‹ï¼Œå¯¦éš›æ‡‰ç”¨éœ€æ›´è¤‡é›œçš„æ•¸æ“šç²å–å’Œè™•ç†)
        try:
            ticker_info = yf.Ticker(stock).info
            df["PE_Ratio"] = ticker_info.get("trailingPE", 0) # ä½¿ç”¨geté¿å…KeyErrorï¼Œé»˜èª0
            df["Market_Cap"] = ticker_info.get("marketCap", 0)
            # åŸºæœ¬é¢æ•¸æ“šé€šå¸¸æ˜¯éœæ…‹çš„ï¼Œéœ€è¦å¡«å……åˆ°æ‰€æœ‰è¡Œ
            df["PE_Ratio"] = df["PE_Ratio"].replace(0, np.nan).ffill().fillna(0)
            df["Market_Cap"] = df["Market_Cap"].replace(0, np.nan).ffill().fillna(0)
        except Exception as e:
            st.warning(f"ç„¡æ³•ç²å–åŸºæœ¬é¢æ•¸æ“š: {e}")
            df["PE_Ratio"] = 0
            df["Market_Cap"] = 0

        feats = [
            "Prev_Close", "MA5", "MA10", "MA20", "MA60",
            "Volume_MA", "Volume_Change",
            "RSI", "MACD", "MACD_Signal", "MACD_Hist",
            "BB_High", "BB_Low", "BB_Mid", "BB_Width",
            "ADX", "DIP", "DIM",
            "K", "D", "J",
            "TWII_Close", "SP500_Close",
            "Volatility", "Daily_Return",
            "PE_Ratio", "Market_Cap"
        ] + [f"Prev_Close_Lag{i}" for i in range(1, 6)]

        # æª¢æŸ¥ä¸¦ç§»é™¤ç¼ºå¤±éå¤šçš„ç‰¹å¾µ
        initial_len = len(df)
        df_cleaned_features = df[feats].dropna()
        if len(df_cleaned_features) < initial_len * 0.8: # å¦‚æœè¶…é20%çš„æ•¸æ“šå› ç‚ºNaNè¢«ç§»é™¤ï¼Œå‰‡è€ƒæ…®ç§»é™¤è©²ç‰¹å¾µ
            for col in feats:
                if df[col].isnull().sum() / initial_len > 0.2:
                    st.warning(f"ç‰¹å¾µ '{col}' ç¼ºå¤±å€¼éå¤šï¼Œå°‡å¾ç‰¹å¾µåˆ—è¡¨ä¸­ç§»é™¤ã€‚")
                    feats.remove(col)

        missing_feats = [f for f in feats if f not in df.columns]
        if missing_feats:
            st.error(f"ç¼ºå°‘ç‰¹å¾µ: {missing_feats}ã€‚è«‹æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§ã€‚")
            return None, None, None

        df_clean = df[feats + ["Close"]].dropna()
        if len(df_clean) < 50: # æé«˜æ¸…ç†å¾Œæ•¸æ“šçš„æœ€ä½è¦æ±‚
            st.error(f"æ¸…ç†å¾Œè³‡æ–™ä¸è¶³ï¼Œåƒ…æœ‰ {len(df_clean)} è¡Œæ•¸æ“šã€‚è«‹å˜—è©¦æ›´é•·çš„æ­·å²æ•¸æ“šç¯„åœæˆ–æ›´æ›è‚¡ç¥¨ã€‚")
            return None, None, None

        X = df_clean[feats].values
        y = df_clean["Close"].values

        X_mean = np.mean(X, axis=0)
        X_std = np.std(X, axis=0)
        X_std[X_std == 0] = 1  # é˜²æ­¢é™¤ä»¥0

        X_normalized = (X - X_mean) / X_std
        weights = np.exp(-decay_factor * np.arange(len(X))[::-1])
        weights = weights / np.sum(weights)

        # æ»¾å‹•æ™‚é–“çª—å£é©—è­‰ (ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰æ›´è¤‡é›œ)
        # é€™è£¡ä»ç„¶ä½¿ç”¨ç°¡å–®çš„80/20åŠƒåˆ†ï¼Œä½†å¯ä»¥è€ƒæ…®åœ¨å¾ŒçºŒéšæ®µå¯¦ç¾æ›´åš´æ ¼çš„å›æ¸¬
        split_idx = int(len(X_normalized) * 0.8)
        X_train, X_val = X_normalized[:split_idx], X_normalized[split_idx:]
        y_train, y_val = y[:split_idx], y[split_idx:]
        train_weights = weights[:split_idx]

        models = []

        # éš¨æ©Ÿæ£®æ—æ¨¡å‹åƒæ•¸å„ªåŒ– (ç¤ºä¾‹ï¼Œå¯¦éš›æ‡‰é€šéGridSearchCVç­‰å„ªåŒ–)
        rf_model = RandomForestRegressor(
            n_estimators=150, # å¢åŠ ä¼°è¨ˆå™¨æ•¸é‡
            max_depth=15,     # å¢åŠ æœ€å¤§æ·±åº¦
            min_samples_split=4,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        rf_model.fit(X_train, y_train, sample_weight=train_weights)
        models.append(("RF1", rf_model))

        rf_model2 = RandomForestRegressor(
            n_estimators=120,
            max_depth=12,
            min_samples_split=3,
            min_samples_leaf=1,
            random_state=123,
            n_jobs=-1
        )
        rf_model2.fit(X_train, y_train, sample_weight=train_weights)
        models.append(("RF2", rf_model2))

        # å¯ä»¥è€ƒæ…®å¼•å…¥å…¶ä»–æ¨¡å‹ï¼Œä¾‹å¦‚XGBoostæˆ–LightGBM
        # from xgboost import XGBRegressor
        # xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
        # xgb_model.fit(X_train, y_train, sample_weight=train_weights)
        # models.append(('XGB', xgb_model))

        last_features = X_normalized[-1:].copy()
        last_close = float(y[-1])
        predictions = {}
        future_dates = []
        current_date = end
        for i in range(5):
            current_date = current_date + pd.offsets.BDay(1)
            future_dates.append(current_date.date())

        current_features = last_features.copy()
        predicted_prices_history = deque([last_close], maxlen=60) # ä½¿ç”¨dequeç¶­è­·æ­·å²åƒ¹æ ¼ï¼Œç”¨æ–¼MAå’Œæ³¢å‹•ç‡è¨ˆç®—

        # å‹•æ…‹èª¿æ•´æœ€å¤§åé›¢é™åˆ¶
        # ä½¿ç”¨æ­·å²æ—¥æ”¶ç›Šç‡çš„æ¨™æº–å·®ä¾†ä¼°è¨ˆæ³¢å‹•ç‡
        daily_returns = df_clean["Daily_Return"].dropna()
        if len(daily_returns) > 30:
            historical_daily_volatility = daily_returns.std()
            # å°‡æ—¥æ³¢å‹•ç‡è½‰æ›ç‚º5æ—¥æ³¢å‹•ç‡çš„è¿‘ä¼¼å€¼ (sqrt(5) * daily_volatility)
            # ä¸¦ä¹˜ä»¥ä¸€å€‹ä¿‚æ•¸ï¼Œä¾‹å¦‚3å€æ¨™æº–å·®ä½œç‚ºåˆç†æ³¢å‹•ç¯„åœ
            max_deviation_pct = historical_daily_volatility * np.sqrt(5) * 3
            max_deviation_pct = min(max_deviation_pct, 0.15) # è¨­å®šä¸Šé™ï¼Œé˜²æ­¢éå¤§
            st.info(f"å‹•æ…‹æœ€å¤§åé›¢é™åˆ¶è¨­å®šç‚º: {max_deviation_pct:.2%}")
        else:
            max_deviation_pct = 0.10 # æ•¸æ“šä¸è¶³æ™‚ä½¿ç”¨é»˜èªå€¼

        for i, date in enumerate(future_dates):
            day_predictions = []
            for model_name, model in models:
                pred = model.predict(current_features)[0]
                # éš¨æ©Ÿè®Šç•°å’Œæ³¢å‹•ç‡èª¿æ•´åƒæ•¸å‹•æ…‹åŒ–
                # éš¨æ©Ÿè®Šç•°åŸºæ–¼é æ¸¬åƒ¹æ ¼å’Œæ­·å²æ³¢å‹•ç‡
                variation_scale = pred * historical_daily_volatility * 0.5 # èª¿æ•´ä¿‚æ•¸
                variation = np.random.normal(0, variation_scale)
                day_predictions.append(pred + variation)

            # å„ªåŒ–é›†æˆç­–ç•¥ï¼šå¯ä»¥è€ƒæ…®åŸºæ–¼æ¨¡å‹åœ¨é©—è­‰é›†ä¸Šçš„è¡¨ç¾ä¾†èª¿æ•´æ¬Šé‡
            # é€™è£¡ä»ç„¶ä½¿ç”¨å›ºå®šæ¬Šé‡ï¼Œä½†å¯ä»¥ä½œç‚ºæœªä¾†æ”¹é€²é»
            weights_ensemble = [0.5, 0.5] # å¦‚æœæœ‰å…©å€‹æ¨¡å‹
            if len(models) == 3: # å¦‚æœæœ‰ä¸‰å€‹æ¨¡å‹
                weights_ensemble = [0.4, 0.3, 0.3]
            ensemble_pred = np.average(day_predictions, weights=weights_ensemble[:len(day_predictions)])

            final_pred = ensemble_pred

            # é™åˆ¶é æ¸¬åƒ¹æ ¼åœ¨åˆç†ç¯„åœå…§
            upper_limit = predicted_prices_history[-1] * (1 + max_deviation_pct)
            lower_limit = predicted_prices_history[-1] * (1 - max_deviation_pct)
            final_pred = min(max(final_pred, lower_limit), upper_limit)

            predictions[date] = float(final_pred)
            predicted_prices_history.append(final_pred) # å°‡æ–°çš„é æ¸¬åƒ¹æ ¼åŠ å…¥æ­·å²è¨˜éŒ„

            if i < 4: # ç‚ºä¸‹ä¸€æ¬¡é æ¸¬æº–å‚™ç‰¹å¾µ
                new_features = current_features[0].copy()

                # æ›´æ–°Prev_Closeå’ŒPrev_Close_Lag
                for j in range(1, 6): # æœ€å¤šæ»¯å¾Œ5å¤©
                    if f"Prev_Close_Lag{j}" in feats:
                        lag_idx = feats.index(f"Prev_Close_Lag{j}")
                        if len(predicted_prices_history) > j:
                            lag_price = predicted_prices_history[-(j + 1)]
                            new_features[lag_idx] = (lag_price - X_mean[lag_idx]) / X_std[lag_idx]

                # æ›´æ–°MA5, MA10, MA20, MA60
                for ma_window in [5, 10, 20, 60]:
                    ma_feat_name = f"MA{ma_window}"
                    if ma_feat_name in feats and len(predicted_prices_history) >= ma_window:
                        ma_idx = feats.index(ma_feat_name)
                        recent_ma = np.mean(list(predicted_prices_history)[-ma_window:])
                        new_features[ma_idx] = (recent_ma - X_mean[ma_idx]) / X_std[ma_idx]

                # æ›´æ–°Volatility
                if "Volatility" in feats and len(predicted_prices_history) >= 10:
                    volatility_idx = feats.index("Volatility")
                    recent_volatility = np.std(list(predicted_prices_history)[-10:])
                    new_features[volatility_idx] = (recent_volatility - X_mean[volatility_idx]) / X_std[volatility_idx]

                # æ›´æ–°Daily_Return
                if "Daily_Return" in feats and len(predicted_prices_history) >= 2:
                    daily_return_idx = feats.index("Daily_Return")
                    current_day_return = (predicted_prices_history[-1] - predicted_prices_history[-2]) / predicted_prices_history[-2]
                    new_features[daily_return_idx] = (current_day_return - X_mean[daily_return_idx]) / X_std[daily_return_idx]

                # å…¶ä»–æŠ€è¡“æŒ‡æ¨™çš„æ›´æ–°æœƒæ›´è¤‡é›œï¼Œé€™è£¡æš«æ™‚ä¿æŒä¸è®Šæˆ–ç°¡åŒ–è™•ç†
                # å¯¦éš›æ‡‰ç”¨ä¸­ï¼Œé€™äº›æŒ‡æ¨™ä¹Ÿéœ€è¦æ ¹æ“šæ–°çš„é æ¸¬åƒ¹æ ¼é€²è¡Œè¿­ä»£è¨ˆç®—

                current_features = new_features.reshape(1, -1)

        preds = {f"T+{i + 1}": pred for i, pred in enumerate(predictions.values())}

        if len(X_val) > 0:
            y_pred_val = models[0][1].predict(X_val)
            mse = mean_squared_error(y_val, y_pred_val)
            rmse = np.sqrt(mse)
            st.info(f"æ¨¡å‹é©—è­‰ - RMSE: {rmse:.2f} (ç´„ {rmse / last_close * 100:.1f}%)")
            feature_importance = models[0][1].feature_importances_
            top_features = sorted(zip(feats, feature_importance), key=lambda x: x[1], reverse=True)[:5]
            st.info(f"é‡è¦ç‰¹å¾µ: {', '.join([f'{feat}({imp:.3f})' for feat, imp in top_features])}")

        return last_close, predictions, preds

    except Exception as e:
        st.error(f"é æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return None, None, None


def get_trade_advice(last, preds):
    if not preds:
        return "ç„¡æ³•åˆ¤æ–·"
    price_changes = [preds[f"T+{d}"] - last for d in range(1, 6)]
    avg_change = np.mean(price_changes)
    change_percent = (avg_change / last) * 100

    # å‹•æ…‹èª¿æ•´äº¤æ˜“é–¾å€¼ (ç¤ºä¾‹ï¼Œå¯¦éš›æ‡‰æ›´è¤‡é›œ)
    # å¯ä»¥æ ¹æ“šæ­·å²æ³¢å‹•ç‡æˆ–å¸‚å ´æƒ…ç·’ä¾†èª¿æ•´
    buy_threshold_strong = 2.5 # æé«˜å¼·çƒˆè²·å…¥é–¾å€¼
    buy_threshold = 0.8      # æé«˜è²·å…¥é–¾å€¼
    sell_threshold_strong = -2.5 # é™ä½å¼·çƒˆè³£å‡ºé–¾å€¼
    sell_threshold = -0.8      # é™ä½è³£å‡ºé–¾å€¼

    if change_percent > buy_threshold_strong:
        return f"å¼·çƒˆè²·å…¥ (é æœŸä¸Šæ¼² {change_percent:.1f}%)"
    elif change_percent > buy_threshold:
        return f"è²·å…¥ (é æœŸä¸Šæ¼² {change_percent:.1f}%)"
    elif change_percent < sell_threshold_strong:
        return f"å¼·çƒˆè³£å‡º (é æœŸä¸‹è·Œ {abs(change_percent):.1f}%)"
    elif change_percent < sell_threshold:
        return f"è³£å‡º (é æœŸä¸‹è·Œ {abs(change_percent):.1f}%)"
    else:
        return f"æŒæœ‰ (é æœŸè®Šå‹• {change_percent:.1f}%)"


# Streamlit UI
st.set_page_config(layout="wide") # è¨­ç½®é é¢ç‚ºå¯¬æ¨¡å¼
st.title("ğŸ“ˆ 5 æ—¥è‚¡åƒ¹é æ¸¬ç³»çµ±")
st.markdown("---")

col1, col2, col3 = st.columns([2, 1, 1]) # å¢åŠ ä¸€åˆ—ç”¨æ–¼è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ
with col1:
    code = st.text_input("è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿ (ä¾‹å¦‚: 2330.TW æˆ– AAPL)", "2330.TW")
with col2:
    mode = st.selectbox("é æ¸¬æ¨¡å¼", ["çŸ­æœŸæ¨¡å¼", "ä¸­æœŸæ¨¡å¼", "é•·æœŸæ¨¡å¼"])
with col3:
    st.markdown("<br>", unsafe_allow_html=True) # ç‚ºäº†å°é½ŠæŒ‰éˆ•
    if st.button("ğŸ”® é–‹å§‹é æ¸¬", type="primary"):
        pass # æŒ‰éˆ•é»æ“Šå¾ŒåŸ·è¡Œä¸‹é¢çš„é‚è¼¯

mode_info = {
    "çŸ­æœŸæ¨¡å¼": ("ä½¿ç”¨ 1 å¹´æ­·å²è³‡æ–™ï¼Œé«˜æ•æ„Ÿåº¦", 365, 0.008),
    "ä¸­æœŸæ¨¡å¼": ("ä½¿ç”¨ 3 å¹´æ­·å²è³‡æ–™ï¼Œå¹³è¡¡æ•æ„Ÿåº¦", 365 * 3, 0.005),
    "é•·æœŸæ¨¡å¼": ("ä½¿ç”¨ 5 å¹´æ­·å²è³‡æ–™ï¼Œä½æ•æ„Ÿåº¦", 365 * 5, 0.002)
}
st.info(f"**{mode}**: {mode_info[mode][0]}")
days, decay_factor = mode_info[mode][1], mode_info[mode][2]

if st.button("ğŸ”® é–‹å§‹é æ¸¬", type="primary", key="predict_button_bottom"):
    full_code = code.strip().upper()
    if not (".TW" in full_code or ".US" in full_code or ".HK" in full_code): # ç°¡å–®åˆ¤æ–·å¸‚å ´
        st.warning("è«‹è¼¸å…¥å®Œæ•´çš„è‚¡ç¥¨ä»£è™Ÿï¼Œä¾‹å¦‚ 2330.TW (å°è‚¡) æˆ– AAPL (ç¾è‚¡)ã€‚")
        full_code = f"{full_code}.TW" # é»˜èªç‚ºå°è‚¡

    with st.spinner("æ­£åœ¨ä¸‹è¼‰è³‡æ–™ä¸¦é€²è¡Œé æ¸¬..."):
        last, forecast, preds = predict_next_5(full_code, days, decay_factor)

    if last is None:
        st.error("âŒ é æ¸¬å¤±æ•—ï¼Œè«‹æª¢æŸ¥è‚¡ç¥¨ä»£è™Ÿæˆ–ç¶²è·¯é€£ç·š")
    else:
        st.success("âœ… é æ¸¬å®Œæˆï¼")

        # é¡¯ç¤ºä¸­è‹±æ–‡è‚¡ç¥¨åç¨±
        company_name = "ç„¡æ³•å–å¾—åç¨±"
        ch_name = stock_name_dict.get(full_code, "ç„¡ä¸­æ–‡åç¨±")
        try:
            ticker_info = yf.Ticker(full_code).info
            company_name = ticker_info.get("shortName") or ticker_info.get("longName") or "ç„¡æ³•å–å¾—åç¨±"
            if ch_name == "ç„¡ä¸­æ–‡åç¨±" and "zh-Hant" in ticker_info.get("summaryProfile", {}).get("language", ""):
                ch_name = ticker_info.get("longName", "ç„¡ä¸­æ–‡åç¨±") # å˜—è©¦å¾yfinanceç²å–ä¸­æ–‡åç¨±
        except Exception:
            pass

        st.write(f"ğŸ“Œ è‚¡ç¥¨åç¨±ï¼š**{ch_name} ({company_name})**")

        col_metric, col_forecast = st.columns([1, 2])
        with col_metric:
            st.metric("ç•¶å‰è‚¡åƒ¹", f"${last:.2f}")
            advice = get_trade_advice(last, preds)
            if "è²·å…¥" in advice:
                st.success(f"ğŸ“ˆ **äº¤æ˜“å»ºè­°**: {advice}")
            elif "è³£å‡º" in advice:
                st.error(f"ğŸ“‰ **äº¤æ˜“å»ºè­°**: {advice}")
            else:
                st.warning(f"ğŸ“Š **äº¤æ˜“å»ºè­°**: {advice}")

            # é¡¯ç¤ºæœ€ä½³è²·è³£é»
            if forecast:
                min_date = min(forecast, key=forecast.get)
                min_price = forecast[min_date]
                max_date = max(forecast, key=forecast.get)
                max_price = forecast[max_date]

                st.markdown("### ğŸ“Œ é æ¸¬æœŸé–“æœ€ä½³è²·è³£é»")
                st.write(f"æœ€ä½³è²·é»ï¼š**{min_date}**ï¼Œé æ¸¬åƒ¹æ ¼ï¼š${min_price:.2f}")
                st.write(f"æœ€ä½³è³£é»ï¼š**{max_date}**ï¼Œé æ¸¬åƒ¹æ ¼ï¼š${max_price:.2f}")

        with col_forecast:
            st.subheader("ğŸ“… æœªä¾† 5 æ—¥é æ¸¬")
            for date, price in forecast.items():
                change = price - last
                change_pct = (change / last) * 100
                if change > 0:
                    st.write(f"**{date}**: ${price:.2f} (<span style='color:green'>+{change:.2f}, +{change_pct:.1f}%</span>)", unsafe_allow_html=True)
                else:
                    st.write(f"**{date}**: ${price:.2f} (<span style='color:red'>{change:.2f}, {change_pct:.1f}%</span>)", unsafe_allow_html=True)

            st.subheader("ğŸ“ˆ é æ¸¬è¶¨å‹¢")
            chart_data = pd.DataFrame({
                "æ—¥æœŸ": ["ä»Šæ—¥"] + list(forecast.keys()),
                "è‚¡åƒ¹": [last] + list(forecast.values())
            })
            # ä½¿ç”¨Plotly Expressæä¾›æ›´è±å¯Œçš„äº¤äº’åœ–è¡¨
            import plotly.express as px
            fig = px.line(chart_data, x="æ—¥æœŸ", y="è‚¡åƒ¹", title="æœªä¾† 5 æ—¥è‚¡åƒ¹é æ¸¬è¶¨å‹¢")
            fig.update_traces(mode='lines+markers')
            st.plotly_chart(fig, use_container_width=True)

st.markdown("---")
st.caption("âš ï¸ æ­¤é æ¸¬åƒ…ä¾›åƒè€ƒï¼ŒæŠ•è³‡æœ‰é¢¨éšªï¼Œè«‹è¬¹æ…æ±ºç­–")


