import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import io
import warnings
from dataclasses import dataclass
from datetime import datetime, time

warnings.filterwarnings("ignore")

# =========================
# Optional: Plotly
# =========================
PLOTLY_ERROR = ""
try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    HAS_PLOTLY = True
except Exception as e:
    HAS_PLOTLY = False
    PLOTLY_ERROR = str(e)

# =========================
# Optional: TW market calendar
# =========================
HAS_TW_CAL = False
try:
    import pandas_market_calendars as mcal
    HAS_TW_CAL = True
except Exception:
    HAS_TW_CAL = False

# =========================
# ML
# =========================
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import HistGradientBoostingRegressor

import ta


# =========================
# Config
# =========================
@dataclass
class Config:
    lookback_days: int = 1200
    forecast_days: int = 10              # ä½ è¦ 10 å¤©
    min_train_rows: int = 240

    # Guard railsï¼ˆé¿å…é æ¸¬çˆ†èµ°ï¼‰
    atr_period: int = 14
    guard_atr_mult: float = 3.0          # MA20 +/- 3*ATR

    # Models
    rf_estimators: int = 300
    rf_max_depth: int = 10
    hgb_max_iter: int = 500

    # Interval and simulation
    interval_z: float = 1.28             # ç´„ 80% å€é–“
    sim_paths: int = 200                 # å¤šæƒ…å¢ƒè·¯å¾‘æ•¸
    sim_noise_mult: float = 1.0          # æ¨¡æ“¬å™ªéŸ³å€ç‡ï¼ˆè¶Šå¤§è¶Šç™¼æ•£ï¼‰
    mean_revert_strength: float = 0.25   # å‡å€¼å›æ­¸å¼·åº¦ï¼ˆ0~1ï¼Œè¶Šå¤§è¶Šä¸å®¹æ˜“å–®é‚Š10å¤©ï¼‰

    # Turning definition (C: RSI + Bollinger)
    rsi_hi: float = 70.0
    rsi_lo: float = 30.0
    bb_window: int = 20
    bb_std: float = 2.0

CFG = Config()


# =========================
# Utilities
# =========================
def safe_download(symbol: str, start: pd.Timestamp, end: pd.Timestamp) -> pd.DataFrame:
    df = yf.download(symbol, start=start, end=end, interval="1d", auto_adjust=True, progress=False)
    if df is None or df.empty:
        return pd.DataFrame()
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = [c[0] for c in df.columns]
    return df

def market_status(code: str) -> str:
    is_tw = code.upper().endswith(".TW")
    if is_tw and HAS_TW_CAL:
        try:
            cal = mcal.get_calendar("XTAI")
            now = pd.Timestamp.now(tz="Asia/Taipei")
            sched = cal.schedule(start_date=now.date(), end_date=now.date())
            if sched.empty:
                return "éäº¤æ˜“æ—¥"
            open_t = sched.iloc[0]["market_open"].tz_convert("Asia/Taipei")
            close_t = sched.iloc[0]["market_close"].tz_convert("Asia/Taipei")
            if open_t <= now <= close_t:
                return "ç›¤ä¸­"
            return "å·²æ”¶ç›¤"
        except Exception:
            pass

    now = datetime.now()
    if now.weekday() >= 5:
        return "éäº¤æ˜“æ—¥(æ¨æ¸¬)"
    if is_tw:
        if time(9, 0) <= now.time() <= time(13, 30):
            return "ç›¤ä¸­(æ¨æ¸¬)"
        return "å·²æ”¶ç›¤(æ¨æ¸¬)"
    return "æ—¥ç·šè³‡æ–™(ä¸åˆ¤æ–·ç›¤ä¸­)"


# =========================
# Feature Engineering
# åªç”¨ Close/Volume ç”¢ç”Ÿæ¨¡å‹ç‰¹å¾µï¼Œæ–¹ä¾¿éè¿´é æ¸¬æ™‚æ›´æ–°ï¼Œé¿å… High/Low è‡ªæˆ‘é¤µé£Ÿæ¼‚ç§»
# =========================
FEATURES = [
    "Ret1", "Ret5",
    "MA5", "MA10", "MA20", "MA60",
    "RSI",
    "Vol20",
    "VolChg"
]

def add_guard_indicators_real(df_raw: pd.DataFrame) -> pd.DataFrame:
    """åªåœ¨çœŸå¯¦æ­·å²è³‡æ–™ä¸Šç®— ATRï¼ˆè­·æ¬„ç”¨ï¼‰"""
    df = df_raw.copy()
    close = df["Close"].astype(float)
    df["MA20"] = close.rolling(20).mean()
    atr = ta.volatility.AverageTrueRange(df["High"], df["Low"], close, window=CFG.atr_period)
    df["ATR"] = atr.average_true_range()
    return df.dropna()

def add_model_features(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()
    close = df["Close"].astype(float)
    vol = df["Volume"].astype(float)

    df["Ret1"] = np.log(close).diff()
    df["Ret5"] = np.log(close).diff(5)

    df["MA5"] = close.rolling(5).mean()
    df["MA10"] = close.rolling(10).mean()
    df["MA20"] = close.rolling(20).mean()
    df["MA60"] = close.rolling(60).mean()

    df["RSI"] = ta.momentum.RSIIndicator(close, window=14).rsi()

    r1 = np.log(close).diff()
    df["Vol20"] = r1.rolling(20).std() * np.sqrt(252)

    df["VolChg"] = vol.pct_change().replace([np.inf, -np.inf], np.nan)

    return df.dropna().copy()

def compute_next_feature_row(close_hist: list[float], vol_hist: list[float]) -> np.ndarray:
    s = pd.Series(close_hist, dtype="float64")
    v = pd.Series(vol_hist, dtype="float64")

    ret1 = float(np.log(s.iloc[-1]) - np.log(s.iloc[-2])) if len(s) >= 2 else 0.0
    ret5 = float(np.log(s.iloc[-1]) - np.log(s.iloc[-6])) if len(s) >= 6 else 0.0

    ma5 = float(s.iloc[-5:].mean()) if len(s) >= 5 else float(s.mean())
    ma10 = float(s.iloc[-10:].mean()) if len(s) >= 10 else float(s.mean())
    ma20 = float(s.iloc[-20:].mean()) if len(s) >= 20 else float(s.mean())
    ma60 = float(s.iloc[-60:].mean()) if len(s) >= 60 else float(s.mean())

    if len(s) >= 15:
        rsi = float(ta.momentum.RSIIndicator(s, window=14).rsi().iloc[-1])
    else:
        rsi = 50.0

    r1 = np.log(s).diff().dropna()
    if len(r1) >= 20:
        vol20 = float(r1.iloc[-20:].std() * np.sqrt(252))
    elif len(r1) >= 2:
        vol20 = float(r1.std() * np.sqrt(252))
    else:
        vol20 = 0.0

    if len(v) >= 2 and v.iloc[-2] != 0:
        volchg = float(v.iloc[-1] / v.iloc[-2] - 1.0)
    else:
        volchg = 0.0

    return np.array([[ret1, ret5, ma5, ma10, ma20, ma60, rsi, vol20, volchg]], dtype="float64")


# =========================
# Models: Ensemble + CV weighting
# =========================
def train_ensemble_with_cv(X: np.ndarray, y: np.ndarray, seed: int = 42):
    models = {
        "HGB": HistGradientBoostingRegressor(
            max_depth=6,
            learning_rate=0.05,
            max_iter=CFG.hgb_max_iter,
            random_state=seed
        ),
        "RF": RandomForestRegressor(
            n_estimators=CFG.rf_estimators,
            max_depth=CFG.rf_max_depth,
            min_samples_split=6,
            random_state=seed,
            n_jobs=-1
        )
    }

    tscv = TimeSeriesSplit(n_splits=5)
    cv_mae = {}

    for name, model in models.items():
        fold_mae = []
        for tr, te in tscv.split(X):
            model.fit(X[tr], y[tr])
            pred = model.predict(X[te])
            fold_mae.append(mean_absolute_error(y[te], pred))
        cv_mae[name] = float(np.mean(fold_mae))

    inv = {k: 1.0 / max(v, 1e-9) for k, v in cv_mae.items()}
    s = sum(inv.values())
    weights = {k: inv[k] / s for k in inv}

    trained = {}
    for name, model in models.items():
        model.fit(X, y)
        trained[name] = model

    return trained, weights, cv_mae

def ensemble_predict(models: dict, weights: dict, X: np.ndarray) -> np.ndarray:
    pred = None
    for name, model in models.items():
        p = model.predict(X)
        w = weights.get(name, 0.0)
        pred = p * w if pred is None else pred + p * w
    return pred

def estimate_sigma(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    resid = (y_true - y_pred)
    if resid.size >= 80:
        resid = resid[-80:]
    return float(np.std(resid))


# =========================
# 10-day forecast (recursive)
# =========================
def forecast_10_days_recursive(models, weights, df_feat: pd.DataFrame, df_raw: pd.DataFrame, df_guard_real: pd.DataFrame):
    future_dates = pd.bdate_range(start=df_feat.index[-1], periods=CFG.forecast_days + 1)[1:]

    close_hist = df_feat["Close"].astype(float).tolist()
    vol_hist = df_raw.loc[df_feat.index, "Volume"].astype(float).tolist()
    future_vol = float(np.mean(vol_hist[-20:])) if len(vol_hist) >= 20 else float(np.mean(vol_hist))

    last_close = float(df_feat["Close"].iloc[-1])

    # guard rails from real MA20/ATR
    if not df_guard_real.empty:
        last_ma20 = float(df_guard_real["MA20"].iloc[-1])
        last_atr = float(df_guard_real["ATR"].iloc[-1])
    else:
        last_ma20 = float(df_feat["MA20"].iloc[-1])
        last_atr = 0.0

    upper = last_ma20 + CFG.guard_atr_mult * last_atr if last_atr > 0 else np.inf
    lower = last_ma20 - CFG.guard_atr_mult * last_atr if last_atr > 0 else -np.inf

    preds = []
    for _ in range(CFG.forecast_days):
        x_next = compute_next_feature_row(close_hist, vol_hist)
        p = float(ensemble_predict(models, weights, x_next)[0])
        p = min(max(p, lower), upper)  # guard
        preds.append(p)

        close_hist.append(p)
        vol_hist.append(future_vol)

    return future_dates, last_close, preds


# =========================
# Turning logic (C: RSI + Bollinger)
# =========================
def compute_rsi_and_bbands(close_series: pd.Series):
    rsi = ta.momentum.RSIIndicator(close_series, window=14).rsi()
    bb = ta.volatility.BollingerBands(close_series, window=CFG.bb_window, window_dev=CFG.bb_std)
    bb_h = bb.bollinger_hband()
    bb_l = bb.bollinger_lband()
    return rsi, bb_h, bb_l


# =========================
# Scenario simulation (multi-path)
# =========================
def simulate_paths_and_turning(df_raw: pd.DataFrame, future_dates, base_preds, sigma: float):
    """
    ç”¨ base_preds ç•¶ driftï¼ŒåŠ å…¥å™ªéŸ³ + å‡å€¼å›æ­¸ï¼Œç”Ÿæˆå¤šæ¢è·¯å¾‘ã€‚
    ç„¶å¾Œçµ±è¨ˆï¼š
      - é€£æ¼²10å¤©/é€£è·Œ10å¤©æ©Ÿç‡
      - æ¯ä¸€å¤©è½‰æŠ˜æ©Ÿç‡ï¼ˆç”±æ¼²è½‰è·Œ / ç”±è·Œè½‰æ¼²ï¼‰
      - æ¯ä¸€å¤©ã€Œå¯èƒ½é«˜é»/ä½é»ã€æ©Ÿç‡ï¼ˆRSI+BB è§¸ç™¼ + æ¬¡æ—¥åè½‰ï¼‰
    """
    n = CFG.sim_paths
    T = len(base_preds)
    last_close = float(df_raw["Close"].iloc[-1])

    # ç”¨æ­·å² close åšå‡å€¼å›æ­¸ç›®æ¨™ï¼ˆMA20ï¼‰
    hist_close = df_raw["Close"].astype(float)
    ma20 = float(hist_close.tail(20).mean()) if len(hist_close) >= 20 else float(hist_close.mean())

    # å¤šæ¢è·¯å¾‘
    paths = np.zeros((n, T), dtype=float)

    # ç”¨ base_preds è½‰æˆ daily driftï¼ˆä»¥ã€Œé æ¸¬å ±é…¬ã€ç•¶ driftï¼‰
    # é¿å… base_preds å–®é‚Šå°è‡´ 10 å¤©éƒ½è·Œï¼šåŠ å…¥ mean-reversion toward MA20
    base = np.array(base_preds, dtype=float)
    base_ret = np.diff(np.log(np.r_[last_close, base]))  # length T

    rng = np.random.default_rng(42)

    for i in range(n):
        c = last_close
        for t in range(T):
            # drift + noise
            noise = rng.normal(0.0, sigma / max(c, 1e-9)) * CFG.sim_noise_mult  # scale to return-ish
            # å‡å€¼å›æ­¸ï¼ˆåƒ¹æ ¼åé›¢ MA20 è¶Šå¤šï¼Œè¶Šæ‹‰å›ï¼‰
            mr = -CFG.mean_revert_strength * ((c - ma20) / max(ma20, 1e-9)) / 10.0

            r = base_ret[t] + mr + noise
            c = c * np.exp(r)
            paths[i, t] = c

    # daily direction (+1 up, -1 down)
    prev = np.r_[np.full((n, 1), last_close), paths[:, :-1]]
    diff = paths - prev
    sign = np.where(diff >= 0, 1, -1)  # (n, T)

    # probability of all-up / all-down
    p_all_up = float(np.mean(np.all(sign == 1, axis=1)) * 100.0)
    p_all_dn = float(np.mean(np.all(sign == -1, axis=1)) * 100.0)

    # turn probability based on sign change
    turn_up_to_dn = np.zeros(T, dtype=float)  # day t: sign(t-1)=+ and sign(t)=- (t>=1)
    turn_dn_to_up = np.zeros(T, dtype=float)

    for t in range(1, T):
        turn_up_to_dn[t] = float(np.mean((sign[:, t-1] == 1) & (sign[:, t] == -1)) * 100.0)
        turn_dn_to_up[t] = float(np.mean((sign[:, t-1] == -1) & (sign[:, t] == 1)) * 100.0)

    # RSI+BB turning probability (top/bottom)
    # å®šç¾©ï¼š
    #   Top day t: (RSI>70 or Close>BB_high) AND next day down
    #   Bottom day t: (RSI<30 or Close<BB_low) AND next day up
    top_prob = np.zeros(T, dtype=float)
    bot_prob = np.zeros(T, dtype=float)

    hist_tail = df_raw["Close"].astype(float).tail(120).copy()

    for t in range(T-1):  # needs t+1
        top_hits = 0
        bot_hits = 0
        for i in range(n):
            sim_close = pd.concat([hist_tail, pd.Series(paths[i, :t+1], index=future_dates[:t+1])], axis=0)
            rsi, bb_h, bb_l = compute_rsi_and_bbands(sim_close)

            c_t = float(sim_close.iloc[-1])
            rsi_t = float(rsi.iloc[-1]) if not np.isnan(rsi.iloc[-1]) else 50.0
            bh_t = float(bb_h.iloc[-1]) if not np.isnan(bb_h.iloc[-1]) else np.inf
            bl_t = float(bb_l.iloc[-1]) if not np.isnan(bb_l.iloc[-1]) else -np.inf

            overbought = (rsi_t >= CFG.rsi_hi) or (c_t >= bh_t)
            oversold = (rsi_t <= CFG.rsi_lo) or (c_t <= bl_t)

            next_move_down = paths[i, t+1] < paths[i, t]
            next_move_up = paths[i, t+1] > paths[i, t]

            if overbought and next_move_down:
                top_hits += 1
            if oversold and next_move_up:
                bot_hits += 1

        top_prob[t] = top_hits / n * 100.0
        bot_prob[t] = bot_hits / n * 100.0

    # build summary tables
    turn_df = pd.DataFrame({
        "æ—¥æœŸ": [d.date() for d in future_dates],
        "ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)": np.round(turn_up_to_dn, 1),
        "ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)": np.round(turn_dn_to_up, 1),
        "å¯èƒ½é«˜é»(%)_RSI+BB": np.round(top_prob, 1),
        "å¯èƒ½ä½é»(%)_RSI+BB": np.round(bot_prob, 1),
    })

    summary = {
        "é€£æ¼²10å¤©æ©Ÿç‡(%)": round(p_all_up, 2),
        "é€£è·Œ10å¤©æ©Ÿç‡(%)": round(p_all_dn, 2),
    }

    return paths, sign, turn_df, summary


# =========================
# UI helpers
# =========================
def pick_top_days(df: pd.DataFrame, col: str, topk: int = 3):
    tmp = df.copy()
    tmp = tmp.sort_values(col, ascending=False).head(topk)
    return tmp[["æ—¥æœŸ", col]]

def plot_history_and_pred(df_raw: pd.DataFrame, future_dates, preds):
    hist = df_raw[["Close"]].tail(120).copy()
    fut = pd.DataFrame({"Close": preds}, index=future_dates)
    merged = pd.concat([hist, fut], axis=0)
    return merged

def plot_k_with_forecast(df_raw: pd.DataFrame, future_dates, preds, lo=None, hi=None):
    if not HAS_PLOTLY:
        return None
    dfp = df_raw.tail(160).copy()
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.06, row_heights=[0.72, 0.28],
                        subplot_titles=("Kç·š + 10æ—¥é æ¸¬", "æˆäº¤é‡"))

    fig.add_trace(go.Candlestick(
        x=dfp.index, open=dfp["Open"], high=dfp["High"], low=dfp["Low"], close=dfp["Close"], name="Kç·š"
    ), row=1, col=1)

    connect_x = [dfp.index[-1]] + list(future_dates)
    connect_y = [float(dfp["Close"].iloc[-1])] + list(preds)
    fig.add_trace(go.Scatter(x=connect_x, y=connect_y, name="é æ¸¬", line=dict(dash="dash", width=3)), row=1, col=1)

    if lo is not None and hi is not None:
        fig.add_trace(go.Scatter(
            x=list(future_dates) + list(future_dates)[::-1],
            y=list(hi) + list(lo)[::-1],
            fill="toself", opacity=0.18,
            line=dict(width=0),
            name="ç´„80%å€é–“"
        ), row=1, col=1)

    fig.add_trace(go.Bar(x=dfp.index, y=dfp["Volume"], name="Volume"), row=2, col=1)
    fig.update_layout(height=700, xaxis_rangeslider_visible=False, hovermode="x unified")
    return fig


# =========================
# Main app
# =========================
st.set_page_config(page_title="AI 10æ—¥è¶¨å‹¢åˆ¤å®šï¼ˆRSI+å¸ƒæ—è½‰æŠ˜ï¼‰", layout="wide", page_icon="ğŸ“ˆ")

st.title("ğŸ“ˆ AI 10æ—¥è¶¨å‹¢åˆ¤å®šï¼ˆä¸åªé æ¸¬åƒ¹æ ¼ï¼šå«è½‰æŠ˜æ©Ÿç‡ã€å–®é‚Šæ©Ÿç‡ã€å¯èƒ½é«˜ä½é»ï¼‰")
st.caption("æ ¸å¿ƒï¼š10æ—¥éè¿´é æ¸¬ + å¤šæƒ…å¢ƒæ¨¡æ“¬ï¼ˆåƒå¤©æ°£é å ±ï¼‰ + è½‰æŠ˜åˆ¤å®šï¼ˆRSI + å¸ƒæ—å¸¶ï¼‰ã€‚")

with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    data_source = st.radio("è³‡æ–™ä¾†æº", ["è‡ªå‹•ä¸‹è¼‰ (yfinance)", "æ‰‹å‹•è²¼ä¸ŠCSVè³‡æ–™"])

    show_interval = st.checkbox("é¡¯ç¤ºé æ¸¬å€é–“ï¼ˆç´„80%ï¼‰", value=True)
    show_plotly = st.checkbox("ä½¿ç”¨ Plotly K ç·šåœ–ï¼ˆéœ€å®‰è£ plotlyï¼‰", value=True)
    sim_paths = st.slider("å¤šæƒ…å¢ƒè·¯å¾‘æ•¸ï¼ˆè¶Šå¤šè¶Šç©©ä½†è¶Šæ…¢ï¼‰", 50, 400, CFG.sim_paths, 50)
    mean_revert = st.slider("å‡å€¼å›æ­¸å¼·åº¦ï¼ˆè¶Šé«˜è¶Šä¸æ˜“10å¤©å–®é‚Šï¼‰", 0.0, 0.8, CFG.mean_revert_strength, 0.05)
    noise_mult = st.slider("æ¨¡æ“¬å™ªéŸ³å€ç‡ï¼ˆè¶Šé«˜è¶Šç™¼æ•£ï¼‰", 0.3, 2.0, CFG.sim_noise_mult, 0.1)

    CFG.sim_paths = int(sim_paths)
    CFG.mean_revert_strength = float(mean_revert)
    CFG.sim_noise_mult = float(noise_mult)

    if data_source == "è‡ªå‹•ä¸‹è¼‰ (yfinance)":
        code = st.text_input("è‚¡ç¥¨ä»£è™Ÿï¼ˆå°è‚¡è¼¸å…¥ 2330ã€ç¾è‚¡ AAPLï¼‰", "2330").strip()
        if code.isdigit():
            code = code + ".TW"
        code = code.upper()

        lookback_days = st.selectbox("è¨“ç·´è³‡æ–™é‡ï¼ˆè¶Šå¤šè¶Šç©©ã€è¶Šæ…¢ï¼‰", [600, 900, 1200, 1600, 2000], index=2)
        st.divider()
        st.write(f"é æ¸¬äº¤æ˜“æ—¥æ•¸ï¼š**{CFG.forecast_days}**")
        st.write(f"å°è‚¡äº¤æ˜“æ—¥æ›†ï¼š{'å·²å•Ÿç”¨(XTAI)' if HAS_TW_CAL else 'æœªå®‰è£ï¼ˆä¸å½±éŸ¿æ ¸å¿ƒåˆ¤å®šï¼‰'}")
    else:
        st.info("æ‰‹å‹• CSV éœ€å« Date, Open, High, Low, Close, Volume æ¬„ä½ã€‚")

run_btn = st.button("ğŸš€ é–‹å§‹åˆ†æ", type="primary", use_container_width=True)

if run_btn:
    # -------- load data --------
    if data_source == "æ‰‹å‹•è²¼ä¸ŠCSVè³‡æ–™":
        manual = st.text_area("è²¼ä¸Š CSVï¼ˆéœ€å« Date, Open, High, Low, Close, Volumeï¼‰", height=240)
        if not manual.strip():
            st.error("è«‹å…ˆè²¼ä¸Š CSVã€‚")
            st.stop()
        try:
            df_raw = pd.read_csv(io.StringIO(manual))
            df_raw["Date"] = pd.to_datetime(df_raw["Date"])
            df_raw = df_raw.set_index("Date").sort_index()
        except Exception as e:
            st.error(f"CSV è§£æå¤±æ•—ï¼š{e}")
            st.stop()
        status = "æ‰‹å‹•è³‡æ–™"
    else:
        status = market_status(code)
        st.info(f"å¸‚å ´ç‹€æ…‹ï¼š**{status}**ï¼ˆæç¤ºç”¨ï¼›æœ¬ç³»çµ±åŸºæ–¼æ—¥ç·šè³‡æ–™ï¼‰")
        end = pd.Timestamp(datetime.today().date()) + pd.Timedelta(days=1)
        start = end - pd.Timedelta(days=int(lookback_days))
        with st.spinner("ä¸‹è¼‰è³‡æ–™ä¸­..."):
            df_raw = safe_download(code, start, end)
        if df_raw.empty:
            st.error("è³‡æ–™ä¸‹è¼‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä»£è™Ÿæˆ–ç¶²è·¯ã€‚")
            st.stop()

    # -------- build features --------
    df_guard = add_guard_indicators_real(df_raw)
    df_feat = add_model_features(df_raw)

    if len(df_feat) < CFG.min_train_rows:
        st.error("æœ‰æ•ˆæ¨£æœ¬ä¸è¶³ï¼šè«‹èª¿é«˜è¨“ç·´è³‡æ–™é‡æˆ–æ›æ¨™çš„ã€‚")
        st.stop()

    # -------- train ensemble --------
    with st.spinner("è¨“ç·´ Ensemble + è¨ˆç®—æ®˜å·®æ³¢å‹•ä¸­..."):
        X = df_feat[FEATURES].values
        y = df_feat["Close"].values
        models, weights, cv_mae = train_ensemble_with_cv(X, y)
        y_pred = ensemble_predict(models, weights, X)
        sigma = estimate_sigma(y, y_pred)

    # -------- forecast 10 days --------
    with st.spinner("é€²è¡Œ 10 æ—¥éè¿´é æ¸¬ä¸­..."):
        future_dates, last_close, base_preds = forecast_10_days_recursive(models, weights, df_feat, df_raw, df_guard)

    # interval for base forecast
    base_hi = [p + CFG.interval_z * sigma for p in base_preds]
    base_lo = [p - CFG.interval_z * sigma for p in base_preds]

    result_df = pd.DataFrame({
        "æ—¥æœŸ": [d.date() for d in future_dates],
        "é æ¸¬åƒ¹": np.round(base_preds, 2),
        "æ¼²è·Œå¹…(ç›¸å°æ˜¨æ”¶)": [f"{(p - last_close) / last_close * 100:+.2f}%" for p in base_preds],
        "å€é–“ä¸‹ç•Œ(ç´„80%)": np.round(base_lo, 2),
        "å€é–“ä¸Šç•Œ(ç´„80%)": np.round(base_hi, 2),
    })

    # -------- simulate multi paths + turning probabilities --------
    with st.spinner("å¤šæƒ…å¢ƒè·¯å¾‘æ¨¡æ“¬ + è½‰æŠ˜æ©Ÿç‡çµ±è¨ˆä¸­..."):
        paths, sign, turn_df, summary = simulate_paths_and_turning(df_raw, future_dates, base_preds, sigma)

    # -------- display summary --------
    st.subheader("ğŸ“Œ æ¨¡å‹æ‘˜è¦")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("æœ€å¾Œæ”¶ç›¤åƒ¹", f"{last_close:.2f}")
    c2.metric("CV MAE (HGB)", f"{cv_mae.get('HGB', np.nan):.3f}")
    c3.metric("CV MAE (RF)", f"{cv_mae.get('RF', np.nan):.3f}")
    c4.metric("æ®˜å·®æ³¢å‹• sigma", f"{sigma:.4f}")

    st.write(f"æ¬Šé‡ï¼šHGB **{weights.get('HGB', 0):.2f}**ï½œRF **{weights.get('RF', 0):.2f}**")

    st.subheader("ğŸ”® 10 å€‹äº¤æ˜“æ—¥é æ¸¬ï¼ˆåŸºæº–è·¯å¾‘ï¼‰")
    if show_interval:
        st.dataframe(result_df, use_container_width=True)
    else:
        st.dataframe(result_df.drop(columns=["å€é–“ä¸‹ç•Œ(ç´„80%)", "å€é–“ä¸Šç•Œ(ç´„80%)"]), use_container_width=True)

    st.subheader("ğŸ§  ä½ è¦çš„ã€åˆ¤å®šã€ï¼šå–®é‚Šæ©Ÿç‡ + è½‰æŠ˜æ—¥ + å¯èƒ½é«˜ä½é»")
    c5, c6 = st.columns(2)
    c5.metric("é€£æ¼²10å¤©æ©Ÿç‡", f"{summary['é€£æ¼²10å¤©æ©Ÿç‡(%)']:.2f}%")
    c6.metric("é€£è·Œ10å¤©æ©Ÿç‡", f"{summary['é€£è·Œ10å¤©æ©Ÿç‡(%)']:.2f}%")

    st.markdown("**è½‰æŠ˜ï¼ˆæ–¹å‘ç¿»è½‰ï¼‰Top 3**")
    t1, t2 = st.columns(2)
    with t1:
        st.write("ç”±æ¼²è½‰è·Œæ©Ÿç‡æœ€é«˜æ—¥ï¼š")
        st.table(pick_top_days(turn_df, "ç”±æ¼²è½‰è·Œæ©Ÿç‡(%)", 3))
    with t2:
        st.write("ç”±è·Œè½‰æ¼²æ©Ÿç‡æœ€é«˜æ—¥ï¼š")
        st.table(pick_top_days(turn_df, "ç”±è·Œè½‰æ¼²æ©Ÿç‡(%)", 3))

    st.markdown("**å¯èƒ½é«˜é» / ä½é»ï¼ˆRSI + å¸ƒæ—å¸¶è§¸ç™¼å¾Œï¼Œæ¬¡æ—¥åè½‰ï¼‰Top 3**")
    b1, b2 = st.columns(2)
    with b1:
        st.write("å¯èƒ½é«˜é»ï¼š")
        st.table(pick_top_days(turn_df, "å¯èƒ½é«˜é»(%)_RSI+BB", 3))
    with b2:
        st.write("å¯èƒ½ä½é»ï¼š")
        st.table(pick_top_days(turn_df, "å¯èƒ½ä½é»(%)_RSI+BB", 3))

    st.subheader("ğŸ“Š è½‰æŠ˜æ©Ÿç‡æ˜ç´°ï¼ˆ10 å¤©é€æ—¥ï¼‰")
    st.dataframe(turn_df, use_container_width=True)

    st.subheader("ğŸ“ˆ èµ°å‹¢ï¼ˆæ­·å² + é æ¸¬ï¼‰")
    merged = plot_history_and_pred(df_raw, future_dates, base_preds)
    st.line_chart(merged)

    if show_plotly and HAS_PLOTLY:
        fig = plot_k_with_forecast(df_raw, future_dates, base_preds,
                                   base_lo if show_interval else None,
                                   base_hi if show_interval else None)
        st.plotly_chart(fig, use_container_width=True)
    elif show_plotly and not HAS_PLOTLY:
        st.warning(f"æœªå®‰è£ plotlyï¼š{PLOTLY_ERROR}")

st.caption("âš ï¸ å…è²¬è²æ˜ï¼šæœ¬å·¥å…·åƒ…ä¾›ç ”ç©¶èˆ‡å­¸ç¿’ï¼Œä¸æ§‹æˆä»»ä½•æŠ•è³‡å»ºè­°ã€‚")
